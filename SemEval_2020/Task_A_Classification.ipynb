{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYDgkKFALhlU"
   },
   "source": [
    "# Importing all the necesary packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score, recall_score\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "QvKrObqJRSjG",
    "outputId": "7466d808-5c54-47fb-e05f-b3371f885aa9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6WGMosjBOu1P"
   },
   "outputs": [],
   "source": [
    "trial_data = pd.read_csv(\"C:\\\\Users\\\\aravi\\\\Desktop\\\\Desktop\\\\SemEval-2020-master\\\\SemEval-2020-master\\\\TrialData\\\\data1.csv\", sep=',')\n",
    "train_data = pd.read_csv(\"C:\\\\Users\\\\aravi\\\\Desktop\\\\Desktop\\\\SemEval-2020-master\\\\SemEval-2020-master\\\\TrainData\\\\data_7000_new.csv\", sep=',', names=['image_name', 'Image_URL', 'OCR_extracted_text', 'corrected_text', 'Humour', 'Sarcasm', 'offensive', 'Motivational', 'Overall_Sentiment', 'Basis_of_classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxbGKwGxO8fd"
   },
   "outputs": [],
   "source": [
    "train_data = train_data[train_data.Overall_Sentiment != 'neutral']\n",
    "train_data = train_data[~train_data.Overall_Sentiment.isnull()]\n",
    "trial_data = trial_data[trial_data.Overall_Sentiment != 'neutral']\n",
    "trial_data = trial_data[~trial_data.Overall_Sentiment.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "zsRTEVPnhWKv",
    "outputId": "ef6fd93b-c35a-4b35-d945-a420aaa7c2ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4448, 10)\n",
      "(637, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(trial_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Removing Punctuation, Numbers, and Special Characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5bXxk_MEQtL8"
   },
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    tweet = re.sub('@(\\\\w{1,15})\\b', '', str(tweet))\n",
    "    tweet = tweet.replace(\"via \", \"\")\n",
    "    tweet = tweet.replace(\"RT \", \"\")\n",
    "    tweet = tweet.lower()\n",
    "    return tweet\n",
    "    \n",
    "def clean_url(tweet):\n",
    "    tweet = re.sub('http\\\\S+', '', tweet, flags=re.MULTILINE)   \n",
    "    return tweet\n",
    "    \n",
    "def remove_stop_words(tweet):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    stops.update(['.',',','\"',\"'\",'?',':',';','(',')','[',']','{','}'])\n",
    "    toks = [tok for tok in tweet if not tok in stops and len(tok) >= 3]\n",
    "    return toks\n",
    "    \n",
    "def stemming_tweets(tweet):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in tweet]\n",
    "    return stemmed_words\n",
    "\n",
    "def remove_number(tweet):\n",
    "    newTweet = re.sub('\\\\d+', '', tweet)\n",
    "    return newTweet\n",
    "\n",
    "def remove_hashtags(tweet):\n",
    "    result = ''\n",
    "\n",
    "    for word in tweet.split():\n",
    "        if word.startswith('#') or word.startswith('@'):\n",
    "            result += word[1:]\n",
    "            result += ' '\n",
    "        else:\n",
    "            result += word\n",
    "            result += ' '\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46OQgx5qQ6wi"
   },
   "outputs": [],
   "source": [
    "def preprocessing(tweet, swords = True, url = True, stemming = True, ctweets = True, number = True, hashtag = True):\n",
    "\n",
    "    if ctweets:\n",
    "        tweet = clean_tweets(tweet)\n",
    "\n",
    "    if url:\n",
    "        tweet = clean_url(tweet)\n",
    "\n",
    "    if hashtag:\n",
    "        tweet = remove_hashtags(tweet)\n",
    "    \n",
    "    twtk = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "    if number:\n",
    "        tweet = remove_number(tweet)\n",
    "    \n",
    "    tokens = [w.lower() for w in twtk.tokenize(tweet) if w != \"\" and w is not None]\n",
    "\n",
    "    if swords:\n",
    "        tokens = remove_stop_words(tokens)\n",
    "\n",
    "    if stemming:\n",
    "        tokens = stemming_tweets(tokens)\n",
    "\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjsNLyUfQ6if"
   },
   "outputs": [],
   "source": [
    "train_text  = train_data['corrected_text'].map(lambda x: preprocessing(x, swords = True, url = True, stemming = True, ctweets = True, number = True, hashtag = True))\n",
    "s_train     = train_data['Overall_Sentiment']\n",
    "\n",
    "trial_text  = trial_data['corrected_text'].map(lambda x: preprocessing(x, swords = True, url = True, stemming = True, ctweets = True, number = True, hashtag = True))\n",
    "s_trial     = trial_data['Overall_Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "16oOYDk2hktd",
    "outputId": "a7cd64c2-b951-4915-d22e-4f9adb69159e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4448 4448\n",
      "637 637\n"
     ]
    }
   ],
   "source": [
    "print(len(train_text), len(s_train))\n",
    "print(len(trial_text), len(s_trial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29jT_5A8RcTm"
   },
   "outputs": [],
   "source": [
    "def bag_of_words(train, test):\n",
    "    vec = CountVectorizer(analyzer='word', binary=True, min_df=1, max_features=25000)\n",
    "    train = vec.fit_transform(train).toarray()\n",
    "    test = vec.transform(test).toarray()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFG9_YpgUa_A"
   },
   "outputs": [],
   "source": [
    "x_train, x_test = bag_of_words(train_text, trial_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "j6erVD0Kl03q",
    "outputId": "e30cebb1-883a-42f9-ee72-256d52e56f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4448, 7590)\n",
      "(637, 7590)\n",
      "4448 637\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(len(s_train), len(s_trial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VefQCQn_Ugda"
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(C=0.1)\n",
    "\n",
    "clf.fit(x_train, s_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "HgSByOrSUyrZ",
    "outputId": "e4eeb504-a42d-4abc-bdf7-3692f403e407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1.........: 0.215056\n",
      "Precision..: 0.503283\n",
      "Recall.....: 0.199376\n",
      "Accuracy...: 0.687598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aravi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\aravi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"F1.........: %f\" %(f1_score(s_trial, y_pred, average=\"macro\")))\n",
    "print(\"Precision..: %f\" %(precision_score(s_trial, y_pred, average=\"macro\")))\n",
    "print(\"Recall.....: %f\" %(recall_score(s_trial, y_pred, average=\"macro\")))\n",
    "print(\"Accuracy...: %f\" %(accuracy_score(s_trial, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Codes_Task_A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
