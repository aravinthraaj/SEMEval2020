{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the necesary packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score, recall_score\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = pd.read_csv(\"C:\\\\Users\\\\aravi\\\\Desktop\\\\Desktop\\\\SemEval-2020-master\\\\SemEval-2020-master\\\\TrialData\\\\data1.csv\", sep=',')\n",
    "train_data = pd.read_csv(\"C:\\\\Users\\\\aravi\\\\Desktop\\\\Desktop\\\\SemEval-2020-master\\\\SemEval-2020-master\\\\TrainData\\\\data_7000_new.csv\", sep=',', names=['image_name', 'Image_URL', 'OCR_extracted_text', 'corrected_text', 'Humour', 'Sarcasm', 'offensive', 'Motivational', 'Overall_Sentiment', 'Basis_of_classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Image_URL</th>\n",
       "      <th>OCR_extracted_text</th>\n",
       "      <th>corrected_text</th>\n",
       "      <th>Humour</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>Motivational</th>\n",
       "      <th>Overall_Sentiment</th>\n",
       "      <th>Basis_of_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_year_2r94rv.jpg</td>\n",
       "      <td>https://i.imgflip.com/2r94rv.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_year_10-year-challenge_1547788782.jpeg</td>\n",
       "      <td>https://spiderimg.amarujala.com/assets/images/...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_year_10yearchallenge-5c75f8b946e0fb0001edc7...</td>\n",
       "      <td>https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_year_10-year-challenge-sweet-dee-edition-40...</td>\n",
       "      <td>https://pics.conservativememes.com/10-year-cha...</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_year_10-year-challenge-with-no-filter-47-hi...</td>\n",
       "      <td>https://pics.me.me/10-year-challenge-with-no-f...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  \\\n",
       "0                                 10_year_2r94rv.jpg   \n",
       "1          10_year_10-year-challenge_1547788782.jpeg   \n",
       "2  10_year_10yearchallenge-5c75f8b946e0fb0001edc7...   \n",
       "3  10_year_10-year-challenge-sweet-dee-edition-40...   \n",
       "4  10_year_10-year-challenge-with-no-filter-47-hi...   \n",
       "\n",
       "                                           Image_URL  \\\n",
       "0                   https://i.imgflip.com/2r94rv.jpg   \n",
       "1  https://spiderimg.amarujala.com/assets/images/...   \n",
       "2  https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...   \n",
       "3  https://pics.conservativememes.com/10-year-cha...   \n",
       "4  https://pics.me.me/10-year-challenge-with-no-f...   \n",
       "\n",
       "                                  OCR_extracted_text  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3             10 Year Challenge - Sweet Dee Edition    \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "                                      corrected_text      Humour  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   hilarious   \n",
       "1  The best of #10 YearChallenge! Completed in le...   not_funny   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...  very_funny   \n",
       "3             10 Year Challenge - Sweet Dee Edition   very_funny   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   hilarious   \n",
       "\n",
       "           Sarcasm       offensive      Motivational Overall_Sentiment  \\\n",
       "0          general   not_offensive  not_motivational     very_positive   \n",
       "1          general   not_offensive      motivational     very_positive   \n",
       "2    not_sarcastic   not_offensive  not_motivational          positive   \n",
       "3  twisted_meaning  very_offensive      motivational          positive   \n",
       "4     very_twisted  very_offensive  not_motivational           neutral   \n",
       "\n",
       "   Basis_of_classification  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dit={\"not_funny\":1,\"not_sarcastic\":2,\"not_offensive\":3,\"funny\":4,\"general\":5,\"slight\":6,\"very_funny\":7,\"twisted_meaning\":8,\"very_offensive\":9,\"hilarious\":10,\"very_twisted\":11,\"hateful_offensive\":12,\"not_motivational\":0,\"motivational\":0,\"very_positive\":0 ,\"positive\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data1(key):\n",
    "    a=list(train_data[key].to_csv(index=False).split('\\n'))\n",
    "    #print(train_data[['Humour','Sarcasm', 'offensive']].to_csv())\n",
    "    #print((a))\n",
    "    hum=[y.replace('\\r', '') for y in a]\n",
    "    hum.pop()\n",
    "    return hum\n",
    "\n",
    "def data2(key):\n",
    "    a=list(trial_data[key].to_csv(index=False).split('\\n'))\n",
    "    #print(train_data[['Humour','Sarcasm', 'offensive']].to_csv())\n",
    "    #print((a))\n",
    "    hum=[y.replace('\\r', '') for y in a]\n",
    "    hum.pop()\n",
    "    return hum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aravi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "a=data1('Humour')\n",
    "b=data1('Sarcasm')\n",
    "c=data1('offensive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6601"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_append=[]\n",
    "for i in range(0,len(train_data)):\n",
    "    for category, num in Dit.items():    \n",
    "        if num == max(Dit[a[i]],Dit[b[i]],Dit[c[i]]):\n",
    "            train_append.append(category)\n",
    "            #print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set(train_append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating the data in to three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hum=['funny','very_funny','hilarious']\n",
    "Sar=['twisted_meaning','very_twisted']\n",
    "off=['slight','very_offensive','hateful_offensive']\n",
    "gen=['not_funny','not_sarcastic','not_offensive','general']\n",
    "for i in range(0,len(train_append)):\n",
    "    if train_append[i] in Hum:\n",
    "        train_append[i]='Humour'\n",
    "    if train_append[i] in Sar:\n",
    "        train_append[i]='Sarcasm'\n",
    "    if train_append[i] in off:\n",
    "        train_append[i]='Offensive'\n",
    "    if train_append[i] in gen:\n",
    "        train_append[i]='General'\n",
    "    #print(train_append[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(train_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_append=pd.Series(train_append)\n",
    "#print((train_append))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['cat']=train_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Image_URL</th>\n",
       "      <th>OCR_extracted_text</th>\n",
       "      <th>corrected_text</th>\n",
       "      <th>Humour</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>Motivational</th>\n",
       "      <th>Overall_Sentiment</th>\n",
       "      <th>Basis_of_classification</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_year_2r94rv.jpg</td>\n",
       "      <td>https://i.imgflip.com/2r94rv.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_year_10-year-challenge_1547788782.jpeg</td>\n",
       "      <td>https://spiderimg.amarujala.com/assets/images/...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_year_10yearchallenge-5c75f8b946e0fb0001edc7...</td>\n",
       "      <td>https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_year_10-year-challenge-sweet-dee-edition-40...</td>\n",
       "      <td>https://pics.conservativememes.com/10-year-cha...</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_year_10-year-challenge-with-no-filter-47-hi...</td>\n",
       "      <td>https://pics.me.me/10-year-challenge-with-no-f...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  \\\n",
       "0                                 10_year_2r94rv.jpg   \n",
       "1          10_year_10-year-challenge_1547788782.jpeg   \n",
       "2  10_year_10yearchallenge-5c75f8b946e0fb0001edc7...   \n",
       "3  10_year_10-year-challenge-sweet-dee-edition-40...   \n",
       "4  10_year_10-year-challenge-with-no-filter-47-hi...   \n",
       "\n",
       "                                           Image_URL  \\\n",
       "0                   https://i.imgflip.com/2r94rv.jpg   \n",
       "1  https://spiderimg.amarujala.com/assets/images/...   \n",
       "2  https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...   \n",
       "3  https://pics.conservativememes.com/10-year-cha...   \n",
       "4  https://pics.me.me/10-year-challenge-with-no-f...   \n",
       "\n",
       "                                  OCR_extracted_text  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3             10 Year Challenge - Sweet Dee Edition    \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "                                      corrected_text      Humour  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   hilarious   \n",
       "1  The best of #10 YearChallenge! Completed in le...   not_funny   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...  very_funny   \n",
       "3             10 Year Challenge - Sweet Dee Edition   very_funny   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   hilarious   \n",
       "\n",
       "           Sarcasm       offensive      Motivational Overall_Sentiment  \\\n",
       "0          general   not_offensive  not_motivational     very_positive   \n",
       "1          general   not_offensive      motivational     very_positive   \n",
       "2    not_sarcastic   not_offensive  not_motivational          positive   \n",
       "3  twisted_meaning  very_offensive      motivational          positive   \n",
       "4     very_twisted  very_offensive  not_motivational           neutral   \n",
       "\n",
       "   Basis_of_classification        cat  \n",
       "0                      NaN     Humour  \n",
       "1                      NaN    General  \n",
       "2                      NaN     Humour  \n",
       "3                      NaN  Offensive  \n",
       "4                      NaN    Sarcasm  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aravi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "d=data2('Humour')\n",
    "e=data2('Sarcasm')\n",
    "f=data2('offensive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_append=[]\n",
    "for i in range(0,len(trial_data)):\n",
    "    for category, num in Dit.items():    \n",
    "        if num == max(Dit[d[i]],Dit[e[i]],Dit[f[i]]):\n",
    "            trial_append.append(category)\n",
    "            #print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hum=['funny','very_funny','hilarious']\n",
    "Sar=['twisted_meaning','very_twisted']\n",
    "off=['slight','very_offensive','hateful_offensive']\n",
    "gen=['not_funny','not_sarcastic','not_offensive','general']\n",
    "for i in range(0,len(trial_append)):\n",
    "    if trial_append[i] in Hum:\n",
    "        trial_append[i]='Humour'\n",
    "    if trial_append[i] in Sar:\n",
    "        trial_append[i]='Sarcasm'\n",
    "    if trial_append[i] in off:\n",
    "        trial_append[i]='Offensive'\n",
    "    if trial_append[i] in gen:\n",
    "        trial_append[i]='General'\n",
    "    #print(trial_append[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data['cat']=trial_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "914"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[train_data.cat != 'General']\n",
    "train_data = train_data[~train_data.cat.isnull()]\n",
    "trial_data = trial_data[trial_data.cat != 'General']\n",
    "trial_data = trial_data[~trial_data.cat.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    tweet = re.sub('@(\\\\w{1,15})\\b', '', str(tweet))\n",
    "    tweet = tweet.replace(\"via \", \"\")\n",
    "    tweet = tweet.replace(\"RT \", \"\")\n",
    "    tweet = tweet.lower()\n",
    "    return tweet\n",
    "    \n",
    "def clean_url(tweet):\n",
    "    tweet = re.sub('http\\\\S+', '', tweet, flags=re.MULTILINE)   \n",
    "    return tweet\n",
    "    \n",
    "def remove_stop_words(tweet):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    stops.update(['.',',','\"',\"'\",'?',':',';','(',')','[',']','{','}'])\n",
    "    toks = [tok for tok in tweet if not tok in stops and len(tok) >= 3]\n",
    "    return toks\n",
    "    \n",
    "def stemming_tweets(tweet):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in tweet]\n",
    "    return stemmed_words\n",
    "\n",
    "def remove_number(tweet):\n",
    "    newTweet = re.sub('\\\\d+', '', tweet)\n",
    "    return newTweet\n",
    "\n",
    "def remove_hashtags(tweet):\n",
    "    result = ''\n",
    "\n",
    "    for word in tweet.split():\n",
    "        if word.startswith('#') or word.startswith('@'):\n",
    "            result += word[1:]\n",
    "            result += ' '\n",
    "        else:\n",
    "            result += word\n",
    "            result += ' '\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(tweet, swords = True, url = True, stemming = True, ctweets = True, number = True, hashtag = True):\n",
    "\n",
    "    if ctweets:\n",
    "        tweet = clean_tweets(tweet)\n",
    "\n",
    "    if url:\n",
    "        tweet = clean_url(tweet)\n",
    "\n",
    "    if hashtag:\n",
    "        tweet = remove_hashtags(tweet)\n",
    "    \n",
    "    twtk = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "    if number:\n",
    "        tweet = remove_number(tweet)\n",
    "    \n",
    "    tokens = [w.lower() for w in twtk.tokenize(tweet) if w != \"\" and w is not None]\n",
    "\n",
    "    if swords:\n",
    "        tokens = remove_stop_words(tokens)\n",
    "\n",
    "    if stemming:\n",
    "        tokens = stemming_tweets(tokens)\n",
    "\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text  = train_data['corrected_text'].map(lambda x: preprocessing(x, swords = True, url = True, stemming = True, ctweets = True, number = True, hashtag = True))\n",
    "s_train     = train_data['cat']\n",
    "\n",
    "trial_text  = trial_data['corrected_text'].map(lambda x: preprocessing(x, swords = True, url = True, stemming = True, ctweets = True, number = True, hashtag = True))\n",
    "s_trial     = trial_data['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(train, test):\n",
    "    vec = CountVectorizer(analyzer='word', binary=True, min_df=1, max_features=25000)\n",
    "    train = vec.fit_transform(train).toarray()\n",
    "    test = vec.transform(test).toarray()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = bag_of_words(train_text, trial_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(C=0.9)\n",
    "\n",
    "clf.fit(x_train, s_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1.........: 0.464096\n",
      "Precision..: 0.686749\n",
      "Recall.....: 0.473062\n",
      "Accuracy...: 0.550409\n"
     ]
    }
   ],
   "source": [
    "print(\"F1.........: %f\" %(f1_score(s_trial, y_pred, average=\"macro\")))\n",
    "print(\"Precision..: %f\" %(precision_score(s_trial, y_pred, average=\"macro\")))\n",
    "print(\"Recall.....: %f\" %(recall_score(s_trial, y_pred, average=\"macro\")))\n",
    "print(\"Accuracy...: %f\" %(accuracy_score(s_trial, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf1 = SVC(kernel = \"linear\", probability = True)\n",
    "clf1.fit(x_train, s_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1.........: 0.447237\n",
      "Precision..: 0.701741\n",
      "Recall.....: 0.461111\n",
      "Accuracy...: 0.543597\n"
     ]
    }
   ],
   "source": [
    "print(\"F1.........: %f\" %(f1_score(s_trial, y_pred, average=\"macro\")))\n",
    "print(\"Precision..: %f\" %(precision_score(s_trial, y_pred, average=\"macro\")))\n",
    "print(\"Recall.....: %f\" %(recall_score(s_trial, y_pred, average=\"macro\")))\n",
    "print(\"Accuracy...: %f\" %(accuracy_score(s_trial, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob=clf1.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34350527, 0.44939564, 0.20709909],\n",
       "       [0.33756903, 0.46585389, 0.19657708],\n",
       "       [0.33346125, 0.48321572, 0.18332304],\n",
       "       ...,\n",
       "       [0.34350527, 0.44939564, 0.20709909],\n",
       "       [0.34350527, 0.44939564, 0.20709909],\n",
       "       [0.34189214, 0.47003245, 0.18807542]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantitation(arr):\n",
    "    \n",
    "    if arr<0.25:\n",
    "        a = 1\n",
    "    elif arr>0.25 and arr<0.50:\n",
    "        a=(2)\n",
    "    elif arr>0.50 and arr<0.75:\n",
    "        a=(3)\n",
    "    elif arr>0.75 and arr<1:\n",
    "        a=(4)\n",
    "    \n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantitation(max(y_prob[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44939564309347124"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_prob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
